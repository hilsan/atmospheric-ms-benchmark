{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe01a1a-449b-419f-a7a4-a9826c90b3d0",
   "metadata": {},
   "source": [
    "2025-11-25. Demo of restructured mass spectrum simulation project\n",
    "\n",
    "This notebook tests my scripts for a small subset of the molecules in my real dataset. \n",
    "In the future, we can use this for a workflow demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f93ccb-6a13-4905-839f-806c70034c41",
   "metadata": {},
   "source": [
    "## 0. Create a toy dataset as a subset from real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f7981-e82f-434a-94ef-823a2f9db07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load full dataset\n",
    "df = pd.read_csv('../data/raw/Franklin/goamazon.csv')\n",
    "\n",
    "# Pick 4 molecules by index:\n",
    "toy_indices = [0, 1, 2, 3]  # first 4 rows for simplicity\n",
    "toy_df = df.iloc[toy_indices].copy()\n",
    "\n",
    "# Duplicate 2 of them, say first and third\n",
    "duplicates = toy_df.iloc[[0, 2]].copy()\n",
    "toy_df = pd.concat([toy_df, duplicates], ignore_index=True)\n",
    "\n",
    "# Save toy dataset\n",
    "toy_df.to_csv('../data/raw/toy_data/toy_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f8acc-82ad-4fdc-ad17-3c9064920b7e",
   "metadata": {},
   "source": [
    "## 1. Remove duplicates from dataset and write smiles in canonical form. Output: A list of SMILES to use as input for derivitization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203f92f-bb5f-48f0-a201-29c890220924",
   "metadata": {},
   "outputs": [],
   "source": [
    "! . ~/.bashrc\n",
    "!echo $SCRIPTS_NEIMS/processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32614ba0-756a-4352-8f2c-072b496a9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /scratch/project_2006752/hsandstr/Project/atmospheric-ms-benchmark/src/processing/remove_duplicate_SMILES_entries.py -i ../data/raw/toy_data/toy_dataset.csv -o ../data/processed/toy_data/toy_dataset_unique.csv  --log_file ../data/processed/toy_data/toy_dataset_duplicates.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3038a-a232-4b9c-98b1-3cafd326b78e",
   "metadata": {},
   "source": [
    "## 2.1 Derivatize molecules. Output: A list of derivatized SMILES for input to MS simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe0375-9d54-4e73-81db-a2c5c8be379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /scratch/project_2006752/hsandstr/Project/atmospheric-ms-benchmark/src/processing/make_TMS_derivative_251125_v1.py --compare_ref \\\n",
    "    -i ../data/processed/toy_data/toy_dataset_unique.csv \\\n",
    "    -o ../data/processed/toy_data_tms/toy_dataset_TMS.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b6051-fb42-49ea-95f1-68d086873ea8",
   "metadata": {},
   "source": [
    "## 3. Make molecule folders and run sdf from smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97562cc-8c85-4350-bc7f-302a082f76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXISTING] Folder exists: 0000\n",
      "  → SMILES file exists, skipping\n",
      "  → Generating SDF\n",
      "  → metadata.json exists, skipping\n",
      "[EXISTING] Folder exists: 0001\n",
      "  → SMILES file exists, skipping\n",
      "  → Generating SDF\n",
      "  → metadata.json exists, skipping\n",
      "[EXISTING] Folder exists: 0002\n",
      "  → SMILES file exists, skipping\n",
      "  → Generating SDF\n",
      "  → metadata.json exists, skipping\n",
      "[EXISTING] Folder exists: 0003\n",
      "  → SMILES file exists, skipping\n",
      "  → Generating SDF\n",
      "  → metadata.json exists, skipping\n"
     ]
    }
   ],
   "source": [
    "%run /scratch/project_2006752/hsandstr/Project/atmospheric-ms-benchmark/src/processing/make_directories_and_sdfs.py  --input_csv ../data/processed/toy_data_tms/toy_dataset_TMS.csv --output_root ../data/simulation_results/toy_dataset_tms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c99e91-6573-4a95-81b0-e93b03698634",
   "metadata": {},
   "source": [
    "## 4.1 Run the initial QCxMS ground state optimization and MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca17f5d2-9ad5-4fa1-88b4-6cb6d6ac679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 30857826\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "sim_dir = os.path.abspath(os.path.join(os.getcwd(), \"../data/simulation_results/toy_dataset_tms/QCxMS_v3/\"))\n",
    "script_path = os.path.abspath(os.path.join(sim_dir, \"../../../../src/workflow/submit_qcxms_gs_md.sh\"))  # adjust path to SLURM script\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"sbatch\", \"--array=0-3\", script_path],\n",
    "    cwd=sim_dir,  # run from toy_data_tms\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005c13f-7dd3-4f75-bb3d-cc18e1f568d3",
   "metadata": {},
   "source": [
    "## 4.2 Run QCxMS fragmentation script for each molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9aed7b-bd47-4588-90bf-92964eb506e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Root simulation directory\n",
    "sim_dir = \"../data/simulation_results/toy_dataset_tms\"\n",
    "script_path = os.path.abspath(os.path.join(sim_dir, \"../../../src/workflow/submit_qcxms_frag_serial.sh\"))\n",
    "# Find all molecule folders (assumes numeric names)\n",
    "molecule_folders = sorted([f for f in os.listdir(sim_dir) if f.isdigit()])\n",
    "\n",
    "for mol in molecule_folders:\n",
    "    mol_path = os.path.join(sim_dir, mol, \"QCxMS\", \"MS-run\")\n",
    "\n",
    "    if not os.path.isdir(mol_path):\n",
    "        print(f\"Skipping {mol}, QCxMS/MS-run folder not found\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Run the SLURM submission script\n",
    "    result = subprocess.run(\n",
    "        [\"bash\", script_path],\n",
    "        cwd=mol_path,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    print(f\"Submitted {mol}:\")\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225eb0e2-9771-4ccf-b7ac-a66911d32e5e",
   "metadata": {},
   "source": [
    "## 4.3 Run QCxMS postprocessing: check that number of successful frag. runs was more than 90 %,\n",
    "## and generate a raw spectra (unfiltered, with floats for m/z numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc1f35b-5747-4c98-8c5d-a263f48e4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 30806746\n",
      "Submitted SLURM array job (toy_dataset_tms_multi.slurm) for 4 directories\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "sim_dir = \"../data/simulation_results/toy_dataset_tms\"\n",
    "script_path = \"../../../src/workflow/submit_qcxms_fragmentation.sh\"\n",
    "\n",
    "result = subprocess.run([\"bash\", script_path], cwd=sim_dir,\n",
    "                        capture_output=True, text=True)\n",
    "\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3403c35-3e57-409f-a9dc-d196d115f443",
   "metadata": {},
   "source": [
    "## 5.1 Run NEIMS for each molecule using the optimized SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d8d0f-f68f-4179-957d-94f291d8ae3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f02667a-648b-4626-92bf-8c75f199790f",
   "metadata": {},
   "source": [
    "## 5.2 Run CFM-ID for compounds it is valid for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24933b1-5397-4aa5-af60-1e78a99b19c5",
   "metadata": {},
   "source": [
    "## 6. Compare NEIMS and QCxMS spectra to eachother and to the reference spectra (choices, binning all peaks to closest integer, then removing peaks with X % of base peak intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f065cc-618b-427c-b8f9-b63bbf16c924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68cef6e0-d3c8-4089-b1c4-a4873e7380b8",
   "metadata": {},
   "source": [
    "## 6.1 Test only using 20 most strong signals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def98b2c-1950-47a5-a312-2580eb1f3ed4",
   "metadata": {},
   "source": [
    "## 7. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af2777-d2a6-4f8e-9645-40e1e1ccf01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
